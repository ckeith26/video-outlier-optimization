{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IgkAjrrIqci0","outputId":"7b79eed9-8b4f-4abb-c0a1-bc975a80efc6"},"outputs":[],"source":["# from google.colab import drive\n","# drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"pBeM8bpOqovJ"},"outputs":[],"source":["import transformers\n","import math\n","import statistics\n","from tqdm import tqdm\n","import torch.nn.functional as F\n","import torch\n","import os\n","import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","from transformers import pipeline\n","from torch.utils.data.dataloader import default_collate\n","from transformers import GPTNeoForCausalLM, GPT2Tokenizer\n","from transformers import BertModel, BertTokenizer, AdamW, get_linear_schedule_with_warmup\n","from torchvision.models import resnet101\n","from torchvision.models import resnet50\n","from sklearn.ensemble import IsolationForest\n","from torch.utils.data import DataLoader , TensorDataset\n","from torch import nn, optim\n","from torchvision import transforms\n","from torchvision.datasets import UCF101"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["2.0.1+cu117\n","True\n","NVIDIA GeForce RTX 3090\n"]}],"source":["print(torch.__version__)\n","print(torch.cuda.is_available())\n","print(torch.cuda.get_device_name(0))"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"U0mwQ6DgBqnW"},"outputs":[],"source":["ucf_data_dir = \"./UCF101/UCF-101/\"\n","path='./ucfTrainTestlist'\n","ucf_label_dir = path\n","frames_per_clip = 5\n","step_between_clips = 1\n","batch_size = 1\n"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"5r2u2Iw-lMIm"},"outputs":[],"source":["tfs = transforms.Compose([\n","            # TODO: this should be done by a video-level transfrom when PyTorch provides transforms.ToTensor() for video\n","            # scale in [0, 1] of type float\n","            transforms.Lambda(lambda x: x / 255.),\n","            # reshape into (T, C, H, W) for easier convolutions\n","            transforms.Lambda(lambda x: x.permute(0, 3, 1, 2)),\n","            # rescale to the most common size\n","            transforms.Lambda(lambda x: nn.functional.interpolate(x, (240, 320))),\n","])"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"051wp921CF89"},"outputs":[],"source":["def custom_collate(batch):\n","    filtered_batch = []\n","    for video, _, label in batch:\n","        filtered_batch.append((video, label))\n","    return torch.utils.data.dataloader.default_collate(filtered_batch)"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wZu-2_uRCKV7","outputId":"f23a0aae-2a9d-418e-ae85-aa313650cd8b"},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 833/833 [03:03<00:00,  4.54it/s]\n","100%|██████████| 833/833 [03:00<00:00,  4.61it/s]\n"]}],"source":["# load train test datasets\n","train_dataset = UCF101(ucf_data_dir, ucf_label_dir, frames_per_clip=frames_per_clip,\n","                       step_between_clips=step_between_clips, train=True, transform=tfs)\n","\n","test_dataset = UCF101(ucf_data_dir, ucf_label_dir, frames_per_clip=frames_per_clip,\n","                      step_between_clips=step_between_clips, train=False, transform=tfs)\n"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"s3Wbuzt0IcKq"},"outputs":[],"source":["\n","train_set, test_set_org = torch.utils.data.random_split(train_dataset,\n","                                                  [1000, 1746933]) # [200000, 1547933]\n","test_set, test_set2 = torch.utils.data.random_split(test_dataset,\n","                                                   [1000, 681084]) # [50000, 632084]"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"TcSjjsLEIgYg"},"outputs":[],"source":["# # create train test test loader (allowing batches and other extras)\n","\n","train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True,\n","                                           collate_fn=custom_collate)\n","test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size, shuffle=True,\n","                                          collate_fn=custom_collate)"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"uapRyJaktbDl"},"outputs":[{"name":"stdout","output_type":"stream","text":["1000\n","1000\n"]}],"source":["batch_size_detector=len(train_set)\n","print(batch_size_detector)\n","outlier_detector = DataLoader(train_set,  batch_size=20, shuffle=True, collate_fn=custom_collate)\n","#batch_size_detector=len(train_set)\n","batch_size_detector2=len(train_set)\n","print(batch_size_detector2)\n","outlier_detector2 = DataLoader(train_set,  batch_size=20, shuffle=True, collate_fn=custom_collate)"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # use gpu if available\n","# def outlier_removal(dataloader=outlier_detector, percentile=5):\n","#   all_preds=[]\n","#   for batch, (X, Y) in enumerate(tqdm(outlier_detector)):\n","\n","#       X, Y = X.to(device=device), Y.to(device)\n","#       print(\"Dataset Loaded!\")\n","#       X_0_1=X[:,0, 0, :,:]\n","#       X_0_1 = X_0_1.reshape(X.shape[0], X_0_1.shape[1]*X_0_1.shape[2])/255.0\n","\n","#       #print(X[0][0])\n","#       val_out=5.00/100.00\n","#       isf = IsolationForest(contamination=val_out, n_jobs=-1)\n","#       X_0_1=X_0_1.cpu().detach().numpy()\n","#       _ = isf.fit(X_0_1)\n","\n","#       # Predictions\n","#       preds = isf.predict(X_0_1)\n","#       pred_list=preds.tolist()\n","#       all_preds.append(preds)\n","#       print(pred_list)\n","#       counter=0\n","#       for i in enumerate(pred_list):\n","#         if (i[1]!=-1):\n","#           counter=counter+1\n","#           #non_outX=X[X[0]!=i[0]]\n","#   for batch, (X, Y) in enumerate(tqdm(outlier_detector2)):\n","\n","#       X, Y = X.to(device=device), Y.to(device)\n","#       #arr = np.array(all_preds)\n","#       non_outX=X[all_preds!=-1]\n","#       print(counter, non_outX.shape)\n"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["# def outlier_removal(dataloader, percentile=5):\n","#     device = torch.device(\"cpu\")\n","#     all_preds = []\n","#     selected_indices = []\n","#     total_samples = 0\n","#     for batch, (X, Y) in enumerate(tqdm(dataloader)):\n","#         X, Y = X.to(device=device), Y.to(device)\n","#         total_samples += X.shape[0]\n","#         X_0_1 = X[:, 0, 0, :, :].reshape(X.shape[0], -1) / 255.0\n","\n","#         val_out = percentile / 100.0\n","#         isf = IsolationForest(contamination=val_out, n_jobs=-1)\n","#         preds = isf.fit_predict(X_0_1.cpu().detach().numpy())  # Move to CPU first\n","#         all_preds.append(preds)\n","\n","#         non_out_indices = np.where(preds != -1)[0]\n","#         if len(non_out_indices) > 0:\n","#             batch_indices = [batch * X.shape[0] + idx for idx in non_out_indices]\n","#             selected_indices.extend(batch_indices)\n","\n","#     if len(selected_indices) == total_samples:\n","#         new_X = torch.index_select(X, 0, torch.tensor(selected_indices).to(device))\n","#         new_Y = torch.index_select(Y, 0, torch.tensor(selected_indices).to(device))\n","#         return TensorDataset(new_X, new_Y)\n","#     else:\n","#         return None"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["import smtplib\n","from email.mime.text import MIMEText\n","\n","def send_email(subject, message):\n","    sender_email = 'cameronkeithgolf@gmail.com'\n","    receiver_email = 'cameronkeithgolf@gmail.com'\n","    smtp_server = 'smtp.gmail.com'\n","    smtp_port = 587\n","    smtp_username = 'cameronkeithgolf@gmail.com'\n","    smtp_password = 'lkhauhjcqytyrarr'\n","\n","    msg = MIMEText(message)\n","    msg['From'] = sender_email\n","    msg['Subject'] = subject\n","    msg['To'] = receiver_email\n","\n","    server = smtplib.SMTP(smtp_server, smtp_port)\n","    server.starttls()\n","    server.login(smtp_username, smtp_password)\n","    server.sendmail(sender_email, receiver_email, msg.as_string())\n","    server.quit()"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"wi8k7U4Gs4nJ"},"outputs":[],"source":["# device = torch.device(\"cpu\")  # use gpu if available\n","def outlier_removal(dataloader=outlier_detector, percentile=5):\n","  all_preds=[]\n","  for batch, (X, Y) in enumerate(tqdm(outlier_detector)):\n","      X, Y = X.to(device=device), Y.to(device)\n","      # print(\"Dataset Loaded!\")\n","      X_0_1=X[:,0, 0, :,:]\n","      X_0_1 = X_0_1.reshape(X.shape[0], X_0_1.shape[1]*X_0_1.shape[2])/255.0\n","\n","      #print(X[0][0])\n","      val_out=5.00/100.00\n","      isf = IsolationForest(contamination=val_out, n_jobs=-1)\n","      X_0_1=X_0_1.cpu().detach().numpy()\n","      _ = isf.fit(X_0_1)\n","\n","      # Predictions\n","      preds = isf.predict(X_0_1)\n","      pred_list=preds.tolist()\n","      all_preds.append(preds)\n","      # print(pred_list)\n","      counter=0\n","      for i in enumerate(pred_list):\n","        if (i[1]!=-1):\n","          counter=counter+1\n","          #non_outX=X[X[0]!=i[0]]\n","  for batch, (X, Y) in enumerate(tqdm(outlier_detector2)):\n","      X, Y = X.to(device=device), Y.to(device)\n","      #arr = np.array(all_preds)\n","      non_outX=X[all_preds!=-1]\n","      # print(counter, non_outX.shape)\n","      outl=X[preds==-1]\n","      non_outl=X[all_preds!=-1]\n","      new_X=non_outl\n","      # print(counter, non_outl.shape)\n","      #new_X[batch*batch_size_train + len(non_outl)-1]=new_X\n","      # print(f'Batch {batch} >> {len(outl)} Outliers {len(non_outl)} Non-Outliers detected with contamination {val_out}')\n","      outl_lab = Y[all_preds==-1]\n","      nonoutl_lab = Y[all_preds!=-1]\n","      new_Y=nonoutl_lab\n","      # print(new_Y.shape)\n","      #new_Y[batch*batch_size_train + len(non_outl)-1]=new_Y\n","      dataset = TensorDataset(new_X , new_Y)\n","\n","      return dataset"]},{"cell_type":"code","execution_count":28,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Qif1iXsxuRPy","outputId":"20caa45b-2d70-4fb0-851f-19a9a68fd84e"},"outputs":[{"name":"stderr","output_type":"stream","text":["  2%|▏         | 1/50 [00:00<00:41,  1.18it/s]c:\\Users\\Cameron Keith\\anaconda3\\envs\\base2\\Lib\\site-packages\\torchvision\\io\\video.py:161: UserWarning: The pts_unit 'pts' gives wrong results. Please use pts_unit 'sec'.\n","  warnings.warn(\"The pts_unit 'pts' gives wrong results. Please use pts_unit 'sec'.\")\n","  4%|▍         | 2/50 [00:01<00:40,  1.18it/s]c:\\Users\\Cameron Keith\\anaconda3\\envs\\base2\\Lib\\site-packages\\torchvision\\io\\video.py:161: UserWarning: The pts_unit 'pts' gives wrong results. Please use pts_unit 'sec'.\n","  warnings.warn(\"The pts_unit 'pts' gives wrong results. Please use pts_unit 'sec'.\")\n","  6%|▌         | 3/50 [00:02<00:41,  1.12it/s]c:\\Users\\Cameron Keith\\anaconda3\\envs\\base2\\Lib\\site-packages\\torchvision\\io\\video.py:161: UserWarning: The pts_unit 'pts' gives wrong results. Please use pts_unit 'sec'.\n","  warnings.warn(\"The pts_unit 'pts' gives wrong results. Please use pts_unit 'sec'.\")\n","  8%|▊         | 4/50 [00:03<00:39,  1.17it/s]c:\\Users\\Cameron Keith\\anaconda3\\envs\\base2\\Lib\\site-packages\\torchvision\\io\\video.py:161: UserWarning: The pts_unit 'pts' gives wrong results. Please use pts_unit 'sec'.\n","  warnings.warn(\"The pts_unit 'pts' gives wrong results. Please use pts_unit 'sec'.\")\n"," 10%|█         | 5/50 [00:04<00:38,  1.18it/s]c:\\Users\\Cameron Keith\\anaconda3\\envs\\base2\\Lib\\site-packages\\torchvision\\io\\video.py:161: UserWarning: The pts_unit 'pts' gives wrong results. Please use pts_unit 'sec'.\n","  warnings.warn(\"The pts_unit 'pts' gives wrong results. Please use pts_unit 'sec'.\")\n"," 12%|█▏        | 6/50 [00:05<00:36,  1.22it/s]c:\\Users\\Cameron Keith\\anaconda3\\envs\\base2\\Lib\\site-packages\\torchvision\\io\\video.py:161: UserWarning: The pts_unit 'pts' gives wrong results. Please use pts_unit 'sec'.\n","  warnings.warn(\"The pts_unit 'pts' gives wrong results. Please use pts_unit 'sec'.\")\n"," 14%|█▍        | 7/50 [00:05<00:33,  1.30it/s]c:\\Users\\Cameron Keith\\anaconda3\\envs\\base2\\Lib\\site-packages\\torchvision\\io\\video.py:161: UserWarning: The pts_unit 'pts' gives wrong results. Please use pts_unit 'sec'.\n","  warnings.warn(\"The pts_unit 'pts' gives wrong results. Please use pts_unit 'sec'.\")\n"," 16%|█▌        | 8/50 [00:06<00:32,  1.28it/s]c:\\Users\\Cameron Keith\\anaconda3\\envs\\base2\\Lib\\site-packages\\torchvision\\io\\video.py:161: UserWarning: The pts_unit 'pts' gives wrong results. Please use pts_unit 'sec'.\n","  warnings.warn(\"The pts_unit 'pts' gives wrong results. Please use pts_unit 'sec'.\")\n"," 18%|█▊        | 9/50 [00:07<00:32,  1.25it/s]c:\\Users\\Cameron Keith\\anaconda3\\envs\\base2\\Lib\\site-packages\\torchvision\\io\\video.py:161: UserWarning: The pts_unit 'pts' gives wrong results. Please use pts_unit 'sec'.\n","  warnings.warn(\"The pts_unit 'pts' gives wrong results. Please use pts_unit 'sec'.\")\n"," 20%|██        | 10/50 [00:08<00:31,  1.26it/s]c:\\Users\\Cameron Keith\\anaconda3\\envs\\base2\\Lib\\site-packages\\torchvision\\io\\video.py:161: UserWarning: The pts_unit 'pts' gives wrong results. Please use pts_unit 'sec'.\n","  warnings.warn(\"The pts_unit 'pts' gives wrong results. Please use pts_unit 'sec'.\")\n"," 22%|██▏       | 11/50 [00:08<00:29,  1.34it/s]c:\\Users\\Cameron Keith\\anaconda3\\envs\\base2\\Lib\\site-packages\\torchvision\\io\\video.py:161: UserWarning: The pts_unit 'pts' gives wrong results. Please use pts_unit 'sec'.\n","  warnings.warn(\"The pts_unit 'pts' gives wrong results. Please use pts_unit 'sec'.\")\n"," 24%|██▍       | 12/50 [00:09<00:29,  1.30it/s]c:\\Users\\Cameron Keith\\anaconda3\\envs\\base2\\Lib\\site-packages\\torchvision\\io\\video.py:161: UserWarning: The pts_unit 'pts' gives wrong results. Please use pts_unit 'sec'.\n","  warnings.warn(\"The pts_unit 'pts' gives wrong results. Please use pts_unit 'sec'.\")\n"," 26%|██▌       | 13/50 [00:10<00:29,  1.27it/s]c:\\Users\\Cameron Keith\\anaconda3\\envs\\base2\\Lib\\site-packages\\torchvision\\io\\video.py:161: UserWarning: The pts_unit 'pts' gives wrong results. Please use pts_unit 'sec'.\n","  warnings.warn(\"The pts_unit 'pts' gives wrong results. Please use pts_unit 'sec'.\")\n"," 28%|██▊       | 14/50 [00:11<00:26,  1.37it/s]c:\\Users\\Cameron Keith\\anaconda3\\envs\\base2\\Lib\\site-packages\\torchvision\\io\\video.py:161: UserWarning: The pts_unit 'pts' gives wrong results. Please use pts_unit 'sec'.\n","  warnings.warn(\"The pts_unit 'pts' gives wrong results. Please use pts_unit 'sec'.\")\n"," 30%|███       | 15/50 [00:11<00:26,  1.32it/s]c:\\Users\\Cameron Keith\\anaconda3\\envs\\base2\\Lib\\site-packages\\torchvision\\io\\video.py:161: UserWarning: The pts_unit 'pts' gives wrong results. Please use pts_unit 'sec'.\n","  warnings.warn(\"The pts_unit 'pts' gives wrong results. Please use pts_unit 'sec'.\")\n"," 32%|███▏      | 16/50 [00:12<00:26,  1.29it/s]c:\\Users\\Cameron Keith\\anaconda3\\envs\\base2\\Lib\\site-packages\\torchvision\\io\\video.py:161: UserWarning: The pts_unit 'pts' gives wrong results. Please use pts_unit 'sec'.\n","  warnings.warn(\"The pts_unit 'pts' gives wrong results. Please use pts_unit 'sec'.\")\n"," 34%|███▍      | 17/50 [00:13<00:26,  1.25it/s]c:\\Users\\Cameron Keith\\anaconda3\\envs\\base2\\Lib\\site-packages\\torchvision\\io\\video.py:161: UserWarning: The pts_unit 'pts' gives wrong results. Please use pts_unit 'sec'.\n","  warnings.warn(\"The pts_unit 'pts' gives wrong results. Please use pts_unit 'sec'.\")\n"," 36%|███▌      | 18/50 [00:14<00:26,  1.19it/s]c:\\Users\\Cameron Keith\\anaconda3\\envs\\base2\\Lib\\site-packages\\torchvision\\io\\video.py:161: UserWarning: The pts_unit 'pts' gives wrong results. Please use pts_unit 'sec'.\n","  warnings.warn(\"The pts_unit 'pts' gives wrong results. Please use pts_unit 'sec'.\")\n"," 38%|███▊      | 19/50 [00:15<00:26,  1.18it/s]c:\\Users\\Cameron Keith\\anaconda3\\envs\\base2\\Lib\\site-packages\\torchvision\\io\\video.py:161: UserWarning: The pts_unit 'pts' gives wrong results. Please use pts_unit 'sec'.\n","  warnings.warn(\"The pts_unit 'pts' gives wrong results. Please use pts_unit 'sec'.\")\n"," 40%|████      | 20/50 [00:16<00:24,  1.20it/s]c:\\Users\\Cameron Keith\\anaconda3\\envs\\base2\\Lib\\site-packages\\torchvision\\io\\video.py:161: UserWarning: The pts_unit 'pts' gives wrong results. Please use pts_unit 'sec'.\n","  warnings.warn(\"The pts_unit 'pts' gives wrong results. Please use pts_unit 'sec'.\")\n"," 42%|████▏     | 21/50 [00:16<00:22,  1.30it/s]c:\\Users\\Cameron Keith\\anaconda3\\envs\\base2\\Lib\\site-packages\\torchvision\\io\\video.py:161: UserWarning: The pts_unit 'pts' gives wrong results. Please use pts_unit 'sec'.\n","  warnings.warn(\"The pts_unit 'pts' gives wrong results. Please use pts_unit 'sec'.\")\n"," 44%|████▍     | 22/50 [00:17<00:22,  1.26it/s]c:\\Users\\Cameron Keith\\anaconda3\\envs\\base2\\Lib\\site-packages\\torchvision\\io\\video.py:161: UserWarning: The pts_unit 'pts' gives wrong results. Please use pts_unit 'sec'.\n","  warnings.warn(\"The pts_unit 'pts' gives wrong results. Please use pts_unit 'sec'.\")\n"," 46%|████▌     | 23/50 [00:18<00:22,  1.20it/s]c:\\Users\\Cameron Keith\\anaconda3\\envs\\base2\\Lib\\site-packages\\torchvision\\io\\video.py:161: UserWarning: The pts_unit 'pts' gives wrong results. Please use pts_unit 'sec'.\n","  warnings.warn(\"The pts_unit 'pts' gives wrong results. Please use pts_unit 'sec'.\")\n"," 48%|████▊     | 24/50 [00:19<00:20,  1.29it/s]c:\\Users\\Cameron Keith\\anaconda3\\envs\\base2\\Lib\\site-packages\\torchvision\\io\\video.py:161: UserWarning: The pts_unit 'pts' gives wrong results. Please use pts_unit 'sec'.\n","  warnings.warn(\"The pts_unit 'pts' gives wrong results. Please use pts_unit 'sec'.\")\n"," 50%|█████     | 25/50 [00:20<00:20,  1.20it/s]c:\\Users\\Cameron Keith\\anaconda3\\envs\\base2\\Lib\\site-packages\\torchvision\\io\\video.py:161: UserWarning: The pts_unit 'pts' gives wrong results. Please use pts_unit 'sec'.\n","  warnings.warn(\"The pts_unit 'pts' gives wrong results. Please use pts_unit 'sec'.\")\n"," 52%|█████▏    | 26/50 [00:20<00:18,  1.30it/s]c:\\Users\\Cameron Keith\\anaconda3\\envs\\base2\\Lib\\site-packages\\torchvision\\io\\video.py:161: UserWarning: The pts_unit 'pts' gives wrong results. Please use pts_unit 'sec'.\n","  warnings.warn(\"The pts_unit 'pts' gives wrong results. Please use pts_unit 'sec'.\")\n"," 54%|█████▍    | 27/50 [00:21<00:18,  1.22it/s]c:\\Users\\Cameron Keith\\anaconda3\\envs\\base2\\Lib\\site-packages\\torchvision\\io\\video.py:161: UserWarning: The pts_unit 'pts' gives wrong results. Please use pts_unit 'sec'.\n","  warnings.warn(\"The pts_unit 'pts' gives wrong results. Please use pts_unit 'sec'.\")\n"," 56%|█████▌    | 28/50 [00:22<00:16,  1.31it/s]c:\\Users\\Cameron Keith\\anaconda3\\envs\\base2\\Lib\\site-packages\\torchvision\\io\\video.py:161: UserWarning: The pts_unit 'pts' gives wrong results. Please use pts_unit 'sec'.\n","  warnings.warn(\"The pts_unit 'pts' gives wrong results. Please use pts_unit 'sec'.\")\n"," 58%|█████▊    | 29/50 [00:23<00:16,  1.30it/s]c:\\Users\\Cameron Keith\\anaconda3\\envs\\base2\\Lib\\site-packages\\torchvision\\io\\video.py:161: UserWarning: The pts_unit 'pts' gives wrong results. Please use pts_unit 'sec'.\n","  warnings.warn(\"The pts_unit 'pts' gives wrong results. Please use pts_unit 'sec'.\")\n"," 60%|██████    | 30/50 [00:24<00:16,  1.21it/s]c:\\Users\\Cameron Keith\\anaconda3\\envs\\base2\\Lib\\site-packages\\torchvision\\io\\video.py:161: UserWarning: The pts_unit 'pts' gives wrong results. Please use pts_unit 'sec'.\n","  warnings.warn(\"The pts_unit 'pts' gives wrong results. Please use pts_unit 'sec'.\")\n"," 62%|██████▏   | 31/50 [00:24<00:15,  1.20it/s]c:\\Users\\Cameron Keith\\anaconda3\\envs\\base2\\Lib\\site-packages\\torchvision\\io\\video.py:161: UserWarning: The pts_unit 'pts' gives wrong results. Please use pts_unit 'sec'.\n","  warnings.warn(\"The pts_unit 'pts' gives wrong results. Please use pts_unit 'sec'.\")\n"," 64%|██████▍   | 32/50 [00:25<00:13,  1.31it/s]c:\\Users\\Cameron Keith\\anaconda3\\envs\\base2\\Lib\\site-packages\\torchvision\\io\\video.py:161: UserWarning: The pts_unit 'pts' gives wrong results. Please use pts_unit 'sec'.\n","  warnings.warn(\"The pts_unit 'pts' gives wrong results. Please use pts_unit 'sec'.\")\n"," 66%|██████▌   | 33/50 [00:26<00:13,  1.30it/s]c:\\Users\\Cameron Keith\\anaconda3\\envs\\base2\\Lib\\site-packages\\torchvision\\io\\video.py:161: UserWarning: The pts_unit 'pts' gives wrong results. Please use pts_unit 'sec'.\n","  warnings.warn(\"The pts_unit 'pts' gives wrong results. Please use pts_unit 'sec'.\")\n"," 68%|██████▊   | 34/50 [00:27<00:12,  1.28it/s]c:\\Users\\Cameron Keith\\anaconda3\\envs\\base2\\Lib\\site-packages\\torchvision\\io\\video.py:161: UserWarning: The pts_unit 'pts' gives wrong results. Please use pts_unit 'sec'.\n","  warnings.warn(\"The pts_unit 'pts' gives wrong results. Please use pts_unit 'sec'.\")\n"," 70%|███████   | 35/50 [00:27<00:11,  1.35it/s]c:\\Users\\Cameron Keith\\anaconda3\\envs\\base2\\Lib\\site-packages\\torchvision\\io\\video.py:161: UserWarning: The pts_unit 'pts' gives wrong results. Please use pts_unit 'sec'.\n","  warnings.warn(\"The pts_unit 'pts' gives wrong results. Please use pts_unit 'sec'.\")\n"," 72%|███████▏  | 36/50 [00:28<00:10,  1.31it/s]c:\\Users\\Cameron Keith\\anaconda3\\envs\\base2\\Lib\\site-packages\\torchvision\\io\\video.py:161: UserWarning: The pts_unit 'pts' gives wrong results. Please use pts_unit 'sec'.\n","  warnings.warn(\"The pts_unit 'pts' gives wrong results. Please use pts_unit 'sec'.\")\n"," 74%|███████▍  | 37/50 [00:29<00:09,  1.32it/s]c:\\Users\\Cameron Keith\\anaconda3\\envs\\base2\\Lib\\site-packages\\torchvision\\io\\video.py:161: UserWarning: The pts_unit 'pts' gives wrong results. Please use pts_unit 'sec'.\n","  warnings.warn(\"The pts_unit 'pts' gives wrong results. Please use pts_unit 'sec'.\")\n"," 76%|███████▌  | 38/50 [00:30<00:09,  1.29it/s]c:\\Users\\Cameron Keith\\anaconda3\\envs\\base2\\Lib\\site-packages\\torchvision\\io\\video.py:161: UserWarning: The pts_unit 'pts' gives wrong results. Please use pts_unit 'sec'.\n","  warnings.warn(\"The pts_unit 'pts' gives wrong results. Please use pts_unit 'sec'.\")\n"," 78%|███████▊  | 39/50 [00:30<00:08,  1.37it/s]c:\\Users\\Cameron Keith\\anaconda3\\envs\\base2\\Lib\\site-packages\\torchvision\\io\\video.py:161: UserWarning: The pts_unit 'pts' gives wrong results. Please use pts_unit 'sec'.\n","  warnings.warn(\"The pts_unit 'pts' gives wrong results. Please use pts_unit 'sec'.\")\n"," 80%|████████  | 40/50 [00:31<00:07,  1.32it/s]c:\\Users\\Cameron Keith\\anaconda3\\envs\\base2\\Lib\\site-packages\\torchvision\\io\\video.py:161: UserWarning: The pts_unit 'pts' gives wrong results. Please use pts_unit 'sec'.\n","  warnings.warn(\"The pts_unit 'pts' gives wrong results. Please use pts_unit 'sec'.\")\n"," 82%|████████▏ | 41/50 [00:32<00:07,  1.27it/s]c:\\Users\\Cameron Keith\\anaconda3\\envs\\base2\\Lib\\site-packages\\torchvision\\io\\video.py:161: UserWarning: The pts_unit 'pts' gives wrong results. Please use pts_unit 'sec'.\n","  warnings.warn(\"The pts_unit 'pts' gives wrong results. Please use pts_unit 'sec'.\")\n"," 84%|████████▍ | 42/50 [00:33<00:06,  1.18it/s]c:\\Users\\Cameron Keith\\anaconda3\\envs\\base2\\Lib\\site-packages\\torchvision\\io\\video.py:161: UserWarning: The pts_unit 'pts' gives wrong results. Please use pts_unit 'sec'.\n","  warnings.warn(\"The pts_unit 'pts' gives wrong results. Please use pts_unit 'sec'.\")\n"," 86%|████████▌ | 43/50 [00:34<00:05,  1.27it/s]c:\\Users\\Cameron Keith\\anaconda3\\envs\\base2\\Lib\\site-packages\\torchvision\\io\\video.py:161: UserWarning: The pts_unit 'pts' gives wrong results. Please use pts_unit 'sec'.\n","  warnings.warn(\"The pts_unit 'pts' gives wrong results. Please use pts_unit 'sec'.\")\n"," 88%|████████▊ | 44/50 [00:34<00:04,  1.29it/s]c:\\Users\\Cameron Keith\\anaconda3\\envs\\base2\\Lib\\site-packages\\torchvision\\io\\video.py:161: UserWarning: The pts_unit 'pts' gives wrong results. Please use pts_unit 'sec'.\n","  warnings.warn(\"The pts_unit 'pts' gives wrong results. Please use pts_unit 'sec'.\")\n"," 90%|█████████ | 45/50 [00:35<00:03,  1.26it/s]c:\\Users\\Cameron Keith\\anaconda3\\envs\\base2\\Lib\\site-packages\\torchvision\\io\\video.py:161: UserWarning: The pts_unit 'pts' gives wrong results. Please use pts_unit 'sec'.\n","  warnings.warn(\"The pts_unit 'pts' gives wrong results. Please use pts_unit 'sec'.\")\n"," 92%|█████████▏| 46/50 [00:36<00:03,  1.27it/s]c:\\Users\\Cameron Keith\\anaconda3\\envs\\base2\\Lib\\site-packages\\torchvision\\io\\video.py:161: UserWarning: The pts_unit 'pts' gives wrong results. Please use pts_unit 'sec'.\n","  warnings.warn(\"The pts_unit 'pts' gives wrong results. Please use pts_unit 'sec'.\")\n"," 94%|█████████▍| 47/50 [00:37<00:02,  1.24it/s]c:\\Users\\Cameron Keith\\anaconda3\\envs\\base2\\Lib\\site-packages\\torchvision\\io\\video.py:161: UserWarning: The pts_unit 'pts' gives wrong results. Please use pts_unit 'sec'.\n","  warnings.warn(\"The pts_unit 'pts' gives wrong results. Please use pts_unit 'sec'.\")\n"," 96%|█████████▌| 48/50 [00:38<00:01,  1.22it/s]c:\\Users\\Cameron Keith\\anaconda3\\envs\\base2\\Lib\\site-packages\\torchvision\\io\\video.py:161: UserWarning: The pts_unit 'pts' gives wrong results. Please use pts_unit 'sec'.\n","  warnings.warn(\"The pts_unit 'pts' gives wrong results. Please use pts_unit 'sec'.\")\n"," 98%|█████████▊| 49/50 [00:38<00:00,  1.22it/s]c:\\Users\\Cameron Keith\\anaconda3\\envs\\base2\\Lib\\site-packages\\torchvision\\io\\video.py:161: UserWarning: The pts_unit 'pts' gives wrong results. Please use pts_unit 'sec'.\n","  warnings.warn(\"The pts_unit 'pts' gives wrong results. Please use pts_unit 'sec'.\")\n","100%|██████████| 50/50 [00:39<00:00,  1.26it/s]\n","  0%|          | 0/50 [00:00<?, ?it/s]c:\\Users\\Cameron Keith\\anaconda3\\envs\\base2\\Lib\\site-packages\\torchvision\\io\\video.py:161: UserWarning: The pts_unit 'pts' gives wrong results. Please use pts_unit 'sec'.\n","  warnings.warn(\"The pts_unit 'pts' gives wrong results. Please use pts_unit 'sec'.\")\n","  0%|          | 0/50 [00:00<?, ?it/s]"]},{"name":"stdout","output_type":"stream","text":["Total number of train samples after outlier removal: 1\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["## percentage of samples to remove\n","psi=5\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # use gpu if available\n","\n","clean_dataset=outlier_removal(dataloader=outlier_detector, percentile=psi)\n","print(f\"Total number of train samples after outlier removal: {len(clean_dataset)}\")\n","\n","train_loader = torch.utils.data.DataLoader(clean_dataset, batch_size=batch_size, shuffle=True,\n","                                           collate_fn=custom_collate)"]},{"cell_type":"code","execution_count":29,"metadata":{"id":"OwyjNZ9Bj583"},"outputs":[],"source":["def custom_collate2(batch):\n","    filtered_batch = []\n","    for video, label in batch:\n","        filtered_batch.append((video, label))\n","    return torch.utils.data.dataloader.default_collate(filtered_batch)"]},{"cell_type":"code","execution_count":30,"metadata":{"id":"N3mEYhPmkAk-"},"outputs":[],"source":["train_loader = torch.utils.data.DataLoader(clean_dataset, batch_size=batch_size, shuffle=True,\n","                                           collate_fn=custom_collate2)"]},{"cell_type":"code","execution_count":31,"metadata":{"id":"SOhCs2ijiE7_"},"outputs":[],"source":["class HLSTMCNN(nn.Module):\n","    def __init__(self, num_classes=101):\n","        super(HLSTMCNN, self).__init__()\n","        self.resnet = resnet50(pretrained=True)\n","        self.resnet.fc = nn.Sequential(nn.Linear(self.resnet.fc.in_features, 300))\n","        self.lstm = nn.LSTM(input_size=300, hidden_size=256, num_layers=3)\n","        self.fc1 = nn.Linear(256, 128)\n","        self.fc2 = nn.Linear(128, num_classes)\n","\n","    def forward(self, x_3d):\n","        hidden = None\n","\n","        # Iterate over each frame of a video in a video of batch * frames * channels * height * width\n","        for t in range(x_3d.size(1)):\n","            with torch.no_grad():\n","                x = self.resnet(x_3d[:, t])\n","            # Pass latent representation of frame through lstm and update hidden state\n","            out, hidden = self.lstm(x.unsqueeze(0), hidden)\n","\n","        # Get the last hidden state (hidden is a tuple with both hidden and cell state in it)\n","        x = self.fc1(hidden[0][-1])\n","        x = F.relu(x)\n","        x = self.fc2(x)\n","\n","        return x"]},{"cell_type":"code","execution_count":32,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\Cameron Keith\\anaconda3\\envs\\base2\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","c:\\Users\\Cameron Keith\\anaconda3\\envs\\base2\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n"]}],"source":["device = torch.device(\"cuda\")  # use gpu if available\n","target_model = HLSTMCNN().to(device=device)\n","optimiser=torch.optim.SGD(target_model.parameters(),lr=0.01,momentum=0.9)\n","cost = torch.nn.CrossEntropyLoss()"]},{"cell_type":"code","execution_count":33,"metadata":{},"outputs":[],"source":["def target_train(train_loader, target_model, optimiser):\n","    target_model.train()\n","    size = len(train_loader.dataset)\n","    correct = 0\n","    total_loss=[]\n","    for batch, (X, Y) in enumerate(tqdm(train_loader)):\n","        X, Y = X.to(device=device), Y.to(device=device)\n","        #print(X.shape, Y.shape)\n","        optimiser.zero_grad()\n","        pred = target_model(X)\n","        #print(pred, Y)\n","        #pred = pred.flatten()\n","        loss = cost(pred, Y)\n","        loss.backward()\n","        optimiser.step()\n","        _, output = torch.max(pred, 1)\n","        #print(output, Y)\n","        correct+= (output == Y).sum().item()\n","        total_loss.append(loss.item())\n","        #batch_count+=batch\n","        #correct += (pred.argmax(1)==Y).type(torch.float).sum().item()\n","\n","    #print(correct, size)\n","    correct /= size\n","    loss= sum(total_loss)/(batch+1)\n","    result_train=100*correct\n","    # torch.save(target_model, './50k_model.pt')\n","    torch.save(target_model, './50k_model_outliers.pt')\n","\n","    print(f'\\nTraining Performance:\\nacc: {(100*correct):>0.1f}%, avg loss: {loss:>8f}\\n')\n","\n","    return loss, result_train\n","\n"]},{"cell_type":"code","execution_count":34,"metadata":{},"outputs":[],"source":["def target_utility(test_loader, target_model, batch_size = batch_size):\n","    size = len(test_loader.dataset)\n","    target_model.eval()\n","    test_loss, correct = 0, 0\n","    correct = 0\n","    total=0\n","    counter_a=0\n","    #with torch.no_grad():\n","    for batch, (X, Y) in enumerate(tqdm(test_loader)):\n","        X, Y = X.to(device=device), Y.to(device=device)\n","        X.requires_grad = True\n","        pred = target_model(X)\n","        #print(\"Y is: \", Y)\n","        counter_a=counter_a+1\n","        #test_loss += cost(pred, Y).item()\n","        total += Y.size(0)\n","        # Forward pass the data through the model\n","        _, output_res = torch.max(pred, -1)\n","        #print(\"pred is: \",output_res)\n","        correct += ((output_res) == Y).sum().item()\n","\n","\n","    # Calculate final accuracy\n","    final_acc = correct/float(total)\n","    print(f\"Target Model Accuracy = {correct} / {total} = {final_acc}\")\n","\n","    # Return the accuracy\n","    return final_acc\n","\n"]},{"cell_type":"code","execution_count":36,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["  0%|          | 0/50 [00:00<?, ?it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch 1\n","-------------------------------\n","+++++++++Target Training Starting+++++++++\n"]},{"name":"stderr","output_type":"stream","text":["  0%|          | 0/1 [00:00<?, ?it/s]\n","  0%|          | 0/50 [00:00<?, ?it/s]\n"]},{"ename":"RuntimeError","evalue":"Expected 3D (unbatched) or 4D (batched) input to conv2d, but got input of size: [1, 5, 3, 240, 320]","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","Cell \u001b[1;32mIn[36], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mt\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m-------------------------------\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m+++++++++Target Training Starting+++++++++\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 6\u001b[0m tr_loss, result_train\u001b[38;5;241m=\u001b[39mtarget_train(train_loader, target_model, optimiser)\n\u001b[0;32m      7\u001b[0m loss_train_tr\u001b[38;5;241m.\u001b[39mappend(tr_loss)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# print('Test Accuracy: ', target_utility(test_loader, target_model, batch_size = batch_size))\u001b[39;00m\n","Cell \u001b[1;32mIn[33], line 10\u001b[0m, in \u001b[0;36mtarget_train\u001b[1;34m(train_loader, target_model, optimiser)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m#print(X.shape, Y.shape)\u001b[39;00m\n\u001b[0;32m      9\u001b[0m optimiser\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 10\u001b[0m pred \u001b[38;5;241m=\u001b[39m target_model(X)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m#print(pred, Y)\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m#pred = pred.flatten()\u001b[39;00m\n\u001b[0;32m     13\u001b[0m loss \u001b[38;5;241m=\u001b[39m cost(pred, Y)\n","File \u001b[1;32mc:\\Users\\Cameron Keith\\anaconda3\\envs\\base2\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n","Cell \u001b[1;32mIn[31], line 16\u001b[0m, in \u001b[0;36mHLSTMCNN.forward\u001b[1;34m(self, x_3d)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(x_3d\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m1\u001b[39m)):\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m---> 16\u001b[0m         x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresnet(x_3d[:, t])\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;66;03m# Pass latent representation of frame through lstm and update hidden state\u001b[39;00m\n\u001b[0;32m     18\u001b[0m     out, hidden \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlstm(x\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m), hidden)\n","File \u001b[1;32mc:\\Users\\Cameron Keith\\anaconda3\\envs\\base2\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n","File \u001b[1;32mc:\\Users\\Cameron Keith\\anaconda3\\envs\\base2\\Lib\\site-packages\\torchvision\\models\\resnet.py:285\u001b[0m, in \u001b[0;36mResNet.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 285\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_impl(x)\n","File \u001b[1;32mc:\\Users\\Cameron Keith\\anaconda3\\envs\\base2\\Lib\\site-packages\\torchvision\\models\\resnet.py:268\u001b[0m, in \u001b[0;36mResNet._forward_impl\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    266\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_forward_impl\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m    267\u001b[0m     \u001b[38;5;66;03m# See note [TorchScript super()]\u001b[39;00m\n\u001b[1;32m--> 268\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv1(x)\n\u001b[0;32m    269\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn1(x)\n\u001b[0;32m    270\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(x)\n","File \u001b[1;32mc:\\Users\\Cameron Keith\\anaconda3\\envs\\base2\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n","File \u001b[1;32mc:\\Users\\Cameron Keith\\anaconda3\\envs\\base2\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:463\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    462\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 463\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_conv_forward(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n","File \u001b[1;32mc:\\Users\\Cameron Keith\\anaconda3\\envs\\base2\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:459\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    456\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[0;32m    457\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[0;32m    458\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[1;32m--> 459\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(\u001b[38;5;28minput\u001b[39m, weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[0;32m    460\u001b[0m                 \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n","\u001b[1;31mRuntimeError\u001b[0m: Expected 3D (unbatched) or 4D (batched) input to conv2d, but got input of size: [1, 5, 3, 240, 320]"]}],"source":["target_epochs=50\n","loss_train_tr, loss_test_tr=[],[]\n","for t in tqdm(range(target_epochs)):\n","    print(f'Epoch {t+1}\\n-------------------------------')\n","    print(\"+++++++++Target Training Starting+++++++++\")\n","    tr_loss, result_train=target_train(train_loader, target_model, optimiser)\n","    loss_train_tr.append(tr_loss)\n","    # print('Test Accuracy: ', target_utility(test_loader, target_model, batch_size = batch_size))\n","\n","    send_email(\n","    f'CNN Training update after {t+1} epochs',\n","    f'''\n","        Train loss: {tr_loss}\n","        Train accuracy: {result_train}\n","        '''\n","    )\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(\"+++++++++Target Test+++++++++\")\n","\n","final_acc=target_utility(test_loader, target_model, batch_size = batch_size)\n","\n","print(f\"Test Acc: {final_acc}\")"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.9"}},"nbformat":4,"nbformat_minor":0}
